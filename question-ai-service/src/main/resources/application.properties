spring.application.name=question-ai-service
server.port=8083

spring.ai.ollama.base-url = http://localhost:11434
# default is = mistral
#spring.ai.ollama.chat.model = llama3.1:8b-instruct-q8_0

